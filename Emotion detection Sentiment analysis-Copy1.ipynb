{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7710081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\ajeeth\\\\Downloads\\\\emotion_dataset_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6246d",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emotion'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1948a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Emotion',data=df,order=df['Emotion'].value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a92a2",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc12c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_calculator(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        result = 'positive'\n",
    "    elif sentiment <0:\n",
    "        result = 'negative'\n",
    "    else:\n",
    "        result = 'neutral'\n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['Text'].apply(sentiment_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11407f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dadf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Emotion','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d64979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising the emotion and sentiment\n",
    "plt.figure(figsize = (8,5))\n",
    "sns.countplot(x='Emotion',data=df,hue='sentiment') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c990ecb",
   "metadata": {},
   "source": [
    "Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neattext.functions as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43329345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(nfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99303089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations\n",
    "df['Clean_Text'] = df['Text'].apply(nfx.remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing usernames\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cdd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96380b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing hashtags\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308303bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing emojis\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb24283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Text','Clean_Text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991bb136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the clean_text columnn(joy) into a list\n",
    "joy_list = df[df['Emotion']=='joy']['Clean_Text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting a list to a doc\n",
    "joy_docs = ''.join(joy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joy_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49230a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#way of approach 1:\n",
    "joy_emotion_keywords = {}\n",
    "for i in joy_docs.split():\n",
    "    if i not in joy_emotion_keywords:\n",
    "        joy_emotion_keywords[i] = 1\n",
    "    else:\n",
    "        joy_emotion_keywords[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c29b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_joy_emotion_keywords = dict(sorted(joy_emotion_keywords.items(), key=lambda item: item[1], reverse=True)[:50])\n",
    "\n",
    "print(common_joy_emotion_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3623fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#way of approach 2:\n",
    "#function for extracting keywords in an emotion\n",
    "from collections import Counter\n",
    "def extract_keywords(text):\n",
    "    tokens = [i for i in text.split()]\n",
    "    x = Counter(tokens).most_common(50)\n",
    "    return dict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0427012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "joy_keyword = extract_keywords(joy_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joy_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ed6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for visualising keywords in an emotion\n",
    "def plotting_keywords(dic,title):\n",
    "    df_1 = pd.DataFrame(data=dic.items(),columns = ['keyword','count'])\n",
    "    plt.figure(figsize = (20,10))\n",
    "    sns.barplot(x='keyword',y='count',data = df_1)\n",
    "    plt.title(f'50 common keywords of {title}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising joy keywords\n",
    "plotting_keywords(joy_keyword,'joy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ef3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0495984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for wordcloud\n",
    "def wordcloud_keyword(text,title):\n",
    "    wc = WordCloud().generate(text)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(f'wordcloud of {title}')\n",
    "    plt.imshow(wc,interpolation='bilinear')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_keyword(joy_docs,'joy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28703a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f53e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting features and labels\n",
    "X = df['Clean_Text']\n",
    "y = df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd2b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c36677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sparse matrix to dense matrix\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e441395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad950a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes model\n",
    "nv_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27654876",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nv_model = nv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366556d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3741a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample coding\n",
    "#sample1 = [\"I love coding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgf = vect.transform(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6842152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgf = vgf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45b719",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#nv_model.predict(vgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nv_model.predict_proba(vgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nv_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9dab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for predicting user customised texts\n",
    "def predict_emotion(samp_txt,model):\n",
    "    samp_txt = vect.transform(samp_txt)\n",
    "    samp_txt = samp_txt.toarray()\n",
    "    prediction = model.predict(samp_txt)\n",
    "    prediction_probablity = model.predict_proba(samp_txt)\n",
    "    all_pred_prob = dict(zip(model.classes_,prediction_probablity[0]))\n",
    "    print(f'{prediction[0]} : {np.max(model.predict_proba(samp_txt))}')\n",
    "    return all_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697289a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_txt = [\"Wow i didn't expect you\"]\n",
    "predict_emotion(samp_txt,nv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd112cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression model\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aab1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr_model = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking accuracy\n",
    "lr_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada46257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samp_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_emotion(samp_txt,lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1eacc4",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report for naive bayes\n",
    "print(classification_report(y_test,pred_nv_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8deec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix plot for naive bayes\n",
    "plot_confusion_matrix(nv_model,X_test,y_test)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df992e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report for logistic reg\n",
    "print(classification_report(y_test,pred_lr_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix plot for logistic reg\n",
    "plot_confusion_matrix(lr_model,X_test,y_test)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc981e7a",
   "metadata": {},
   "source": [
    "Serialize and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69bfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the naive bayes model using pickle modue\n",
    "model_save = open(\"Text_Classification_sentiment_analysis_nv_model.pkl\",\"wb\")\n",
    "joblib.dump(nv_model,model_save)\n",
    "model_save.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the logistic reg model using pickle modue\n",
    "model_save = open(\"Text_Classification_sentiment_analysis_lr_model.pkl\",\"wb\")\n",
    "joblib.dump(lr_model,model_save)\n",
    "model_save.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae001ebd",
   "metadata": {},
   "source": [
    "Emotion Detection in Text: An End-to-End NLP Pipeline Using Logistic Regression\n",
    "\n",
    "Objective:\n",
    "The primary goal of this project is to develop a robust and efficient pipeline for detecting emotions in text using Natural Language Processing (NLP) techniques and machine learning. By leveraging logistic regression, naive bayes the project aims to classify text into various emotional categories such as joy, sadness, anger, fear, and others.\n",
    "\n",
    "Dataset:\n",
    "The project utilizes a dataset containing text samples labeled with corresponding emotions. The dataset is loaded and inspected to understand the distribution of emotions and prepare for subsequent processing.\n",
    "\n",
    "Methodology:\n",
    "\n",
    "Data Exploration and Visualization:\n",
    "\n",
    "Load the dataset using pandas and explore the distribution of emotions using value counts.\n",
    "Visualize the data distribution using seaborn to understand the frequency of each emotion category.\n",
    "\n",
    "Data Cleaning:\n",
    "\n",
    "Employ the neattext library to clean the text data by removing user handles, stopwords, and other irrelevant components.\n",
    "Create a new column Clean_Text in the dataframe to store the cleaned text.\n",
    "\n",
    "Feature Engineering:\n",
    "\n",
    "Define features (cleaned text) and labels (emotions) for the model.\n",
    "Split the data into training and test sets using train_test_split from sklearn.\n",
    "\n",
    "Model Building:\n",
    "\n",
    "Construct a machine learning pipeline using sklearn's Pipeline.\n",
    "Integrate CountVectorizer for text vectorization and LogisticRegression for classification.\n",
    "Train the logistic regression model on the training data.\n",
    "\n",
    "Model Evaluation:\n",
    "\n",
    "Evaluate the modelâ€™s performance on the test set using accuracy score and classification report.\n",
    "Assess model predictions and prediction probabilities for individual text samples.\n",
    "\n",
    "Model Saving:\n",
    "\n",
    "Save the trained model pipeline using joblib for future use and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc21e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
